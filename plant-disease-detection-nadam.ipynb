{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7418691,"sourceType":"datasetVersion","datasetId":4315922}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n!pip install torchvision\n!pip install seaborn\n!pip install tqdm\n!pip install torchaudio\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torchvision.utils import make_grid\nfrom tqdm.notebook import tqdm\nimport random\nimport warnings\nfrom PIL import Image\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.manual_seed(42)\nrandom.seed(42)\nnp.random.seed(42)\n\ndata_path = '/kaggle/input/crop-disease-detection-dataset/Plant Village Dataset/'\ntrain_folder = os.path.join(data_path, 'Train')\ntest_folder = os.path.join(data_path, 'Test')\nval_folder = os.path.join(data_path,'Val')\n\nclasses = os.listdir(train_folder)\nunique_plant_diseases = []\nfor item in classes:\n    disease = item.split('_')[0]\n    if disease not in unique_plant_diseases:\n        unique_plant_diseases.append(disease)\nprint(\"Number of unique plant diseases:\", len(unique_plant_diseases))\nprint(\"Plants:\", unique_plant_diseases)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((224, 224)),  # VGG16 expects 224x224 images\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.2),\n    transforms.RandomRotation(20),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_ds = ImageFolder(train_folder, transform=train_transform)\ntest_ds = ImageFolder(test_folder, transform=eval_transform)\nval_ds = ImageFolder(val_folder, transform=eval_transform)\n\nprint(\"Number of training images:\", len(train_ds))\nprint(\"Number of test images:\", len(test_ds))\nprint(\"Number of validation images:\", len(val_ds))\nprint(\"Number of classes:\", len(train_ds.classes))\nprint(\"Classes:\", train_ds.classes)\n\nimg, label = train_ds[4587]\nprint(\"Image shape:\", img.shape)\nprint(\"Label:\", label, train_ds.classes[label])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to denormalize images for visualization\ndef denormalize(tensor):\n    mean = torch.tensor([0.485, 0.456, 0.406]).reshape(3, 1, 1)\n    std = torch.tensor([0.229, 0.224, 0.225]).reshape(3, 1, 1)\n    return tensor * std + mean\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nax1.imshow(denormalize(img).permute(1, 2, 0).clamp(0, 1))\nax1.set_title(\"Original Image\")\nax2.imshow(1 - denormalize(img).permute(1, 2, 0).clamp(0, 1))\nax2.set_title(\"Inverted Image\")\nplt.show()\n\ntrain_data_overview = DataLoader(train_ds, batch_size=32, shuffle=True)\nimages, labels = next(iter(train_data_overview))\nsample_indices = random.sample(range(len(images)), 6)\nplt.figure(figsize=(20, 4))\nfor i, idx in enumerate(sample_indices):\n    plt.subplot(1, 6, i+1)\n    plt.imshow(denormalize(images[idx]).permute(1, 2, 0).clamp(0, 1))\n    plt.title(f\"{train_ds.classes[labels[idx]]}\")\n    plt.axis(\"off\")\nplt.suptitle(\"Dataset Overview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n6 Random Training Images.\", fontsize=15)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Increased batch size for faster training and better gradient estimates\nbatch_size = 64\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n\nfor imgs, lbls in train_loader:\n    plt.figure(figsize=(20, 8))\n    plt.imshow(make_grid(denormalize(imgs), nrow=16).permute(1, 2, 0).clamp(0, 1))\n    plt.axis('off')\n    break\n\ndiseases = os.listdir(train_folder)\nclass_counts = {cls: len(os.listdir(os.path.join(train_folder, cls))) for cls in diseases}\ndf = pd.DataFrame(list(class_counts.items()), columns=[\"Disease Class\", \"Number of Images\"])\nplt.figure(figsize=(15,5))\nsns.barplot(data=df, x='Disease Class', y='Number of Images')\nplt.xticks(rotation=90)\nplt.title(\"Dataset Distribution\\nNumber of Images per Disease Class.\")\nplt.show()\n\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {'val_loss': loss, 'val_acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_loss = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_loss).mean()\n        batch_acc = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_acc).mean()\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(f\"Epoch [{epoch}], train_loss: {result['train_loss']:.4f}, val_loss: {result['val_loss']:.4f}, val_acc: {result['val_acc']:.4f}\")\n\nclass Plant_Disease_VGG16(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Load pre-trained VGG16 model\n        self.network = models.vgg16(pretrained=True)\n        \n        # Freeze more layers for fine-tuning\n        for param in list(self.network.features.parameters())[:-8]:  # Freeze more early layers\n            param.requires_grad = False\n            # Get the number of input features for the classifier\n        num_ftrs = self.network.classifier[-1].in_features\n        \n        # Replace the classifier with our custom classifier\n        # Added an additional layer for better feature representation\n        self.network.classifier = nn.Sequential(\n            nn.Linear(25088, 4096),\n            nn.ReLU(True),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 2048),  # Added layer (original VGG16 has 4096->4096->1000)\n            nn.ReLU(True),\n            nn.Dropout(0.5),\n            nn.Linear(2048, 1024),\n            nn.ReLU(True),\n            nn.Dropout(0.5),\n            nn.Linear(1024, 38)  # Output layer for 38 classes\n        )\n        \n        # Initialize the weights of the new layers\n        for m in self.network.classifier.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n    \n    def forward(self, xb):\n        return self.network(xb)\n\ndef get_default_device():\n    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\ndef to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n    \n    def __iter__(self):\n        for b in self.dl:\n            yield to_device(b, self.device)\n    \n    def __len__(self):\n        return len(self.dl)\n\ndevice = get_default_device()\nprint(\"Using device:\", device)\n\nvgg_model_ft = Plant_Disease_VGG16()\nprint(vgg_model_ft)  # Check model before moving to device\nvgg_model_ft = to_device(vgg_model_ft, device)\nprint(vgg_model_ft)  # Check if it moves successfully\n\ntrain_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    # Using NAdam with improved parameters\n    optimizer = opt_func(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n    \n    # Learning rate scheduler for better convergence\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n    \n    best_val_acc = 0.0\n    for epoch in range(epochs):\n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping to prevent exploding gradients\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n        \n        torch.cuda.empty_cache()\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n        \n        # Step the scheduler based on validation loss\n        scheduler.step(result['val_loss'])\n        \n        # Save the best model based on validation accuracy\n        if result['val_acc'] > best_val_acc:\n            best_val_acc = result['val_acc']\n            torch.save(model.state_dict(), 'best_model.pth')\n            print(f\"Model saved with val_acc: {best_val_acc:.4f}\")\n    \n    # Load the best model before returning\n    model.load_state_dict(torch.load('best_model.pth'))\n    return history\n\n# Increased epochs and adjusted learning rate for better convergence\nhistory_vgg_ft = fit(40, 0.0001, vgg_model_ft, train_loader, val_loader, opt_func=torch.optim.NAdam)\n\ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.figure(figsize=(10, 6))\n    plt.plot(train_losses, '-bx', label=\"Train Loss\")\n    plt.plot(val_losses, '-rx', label=\"Val Loss\")\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Loss vs. Epochs')\n    plt.grid(True)\n    plt.show()\n\ndef plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.figure(figsize=(10, 6))\n    plt.plot(accuracies, '-x', color='green')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy vs. Epochs')\n    plt.grid(True)\n    plt.show()\n\nplot_accuracies(history_vgg_ft)\nplot_losses(history_vgg_ft)\n\nprint(\"Evaluation on Test Set (Fine-tuned VGG16):\")\nprint(evaluate(vgg_model_ft, test_loader))\n\n# Generate confusion matrix\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np\n\ndef plot_confusion_matrix(model, test_loader, classes):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(20, 20))\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    \n    thresh = cm.max() / 2\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            plt.text(j, i, format(cm[i, j], 'd'),\n                    horizontalalignment=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n    \n    print(classification_report(all_labels))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the complete model\ntorch.save(vgg_model_ft, 'plant_disease_model_complete.pth')\n\n# Save just the state dictionary (recommended, more portable)\ntorch.save(vgg_model_ft.state_dict(), 'plant_disease_model_state_dict.pth')\n\n# Save model architecture and parameters as a checkpoint\n\"\"\"checkpoint = {\n    'model_state_dict': vgg_model_ft.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),  # assuming optimizer is still in scope\n    'classes': train_ds.classes,\n    'epoch': len(history_vgg_ft)\n}\ntorch.save(checkpoint, 'plant_disease_model_checkpoint.pth')\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}